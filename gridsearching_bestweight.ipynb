{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f5a38-d4b6-41df-9809-e462a778045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import time, random, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# Configuration\n",
    "# =========================\n",
    "SEEDS = [42, 43, 44, 45, 46]   # Multiple random seeds\n",
    "IMBALANCE_RATIO = 0.98         # Training set: ratio of digit 9 (majority); digit 4 (minority) ratio = 1 - IMBALANCE_RATIO\n",
    "TOTAL_TRAIN = 5000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "ERM_STEPS = 8000               # Number of training steps for ERM baseline\n",
    "GRID_STEP = 0.02               # Step size for grid search\n",
    "STEPS_PER_GRID = 8000          # Number of training steps for each p4 in grid search\n",
    "LR = 1e-3\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.0\n",
    "\n",
    "TEST_MAJ_RATIO = 0.50          # Test set fixed at 50/50 ratio (likelihood ratio p4=0.5)\n",
    "P4_TRAIN_PRIOR = 1.0 - IMBALANCE_RATIO  # p4 prior in training set\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# =========================\n",
    "# Utility functions\n",
    "# =========================\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "\n",
    "def load_mnist_49():\n",
    "    \"\"\"Load MNIST dataset and keep only digits 4 and 9.\"\"\"\n",
    "    tf = transforms.ToTensor()\n",
    "    tr = datasets.MNIST(\"./data\", train=True,  download=True, transform=tf)\n",
    "    te = datasets.MNIST(\"./data\", train=False, download=True, transform=tf)\n",
    "\n",
    "    def filt(ds):\n",
    "        xs, ys = [], []\n",
    "        for i in range(len(ds)):\n",
    "            x, y = ds[i]\n",
    "            if y in (4, 9):\n",
    "                xs.append(x)\n",
    "                ys.append(0 if y == 4 else 1)  # map 4->0 (minority), 9->1 (majority)\n",
    "        return torch.stack(xs), torch.tensor(ys, dtype=torch.long)\n",
    "\n",
    "    Xtr, ytr = filt(tr)\n",
    "    Xte, yte = filt(te)\n",
    "    return Xtr, ytr, Xte, yte\n",
    "\n",
    "def sample_imbalanced_train(X, y, total, maj_ratio, seed):\n",
    "    \"\"\"Sample imbalanced training data given majority ratio.\"\"\"\n",
    "    set_seed(seed)\n",
    "    idx4 = (y==0).nonzero(as_tuple=True)[0]\n",
    "    idx9 = (y==1).nonzero(as_tuple=True)[0]\n",
    "    n_maj = int(total*maj_ratio)\n",
    "    n_min = total - n_maj\n",
    "    sel9 = idx9[torch.randperm(len(idx9))[:n_maj]]\n",
    "    sel4 = idx4[torch.randperm(len(idx4))[:n_min]]\n",
    "    idx  = torch.cat([sel4, sel9], dim=0)\n",
    "    idx  = idx[torch.randperm(len(idx))]\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "def build_test_with_ratio(X, y, maj_ratio=0.5, total=1000):\n",
    "    \"\"\"Build a balanced test set with specified majority ratio.\"\"\"\n",
    "    n_maj = int(total * maj_ratio)\n",
    "    n_min = total - n_maj\n",
    "    idx4 = (y==0).nonzero(as_tuple=True)[0][:n_min]\n",
    "    idx9 = (y==1).nonzero(as_tuple=True)[0][:n_maj]\n",
    "    idx = torch.cat([idx4, idx9], dim=0)\n",
    "    idx = idx[torch.randperm(len(idx))]\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    \"\"\"Standard LeNet-5 architecture.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool  = nn.AvgPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*4*4, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 28->24->12\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 12->8->4\n",
    "        x = x.view(x.size(0), -1)             # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "ce = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "def compute_weighted_loss(logits, targets, p_vec, p_train_vec):\n",
    "    \"\"\"Compute weighted cross-entropy loss based on group weights.\"\"\"\n",
    "    w = p_vec[targets] / p_train_vec[targets]\n",
    "    losses = ce(logits, targets)\n",
    "    return (losses * w).mean()\n",
    "\n",
    "def train_steps(model, loader, steps, p_vec, p_train_vec, lr=LR, momentum=MOMENTUM, wd=WEIGHT_DECAY, verbose_every=0):\n",
    "    \"\"\"Train the model for a fixed number of steps.\"\"\"\n",
    "    model.train()\n",
    "    opt = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=wd)\n",
    "    it = iter(loader)\n",
    "    for s in range(1, steps+1):\n",
    "        try:\n",
    "            xb, yb = next(it)\n",
    "        except StopIteration:\n",
    "            it = iter(loader)\n",
    "            xb, yb = next(it)\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = compute_weighted_loss(logits, yb, p_vec, p_train_vec)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if verbose_every and s % verbose_every == 0:\n",
    "            print(f\"[train] step {s}/{steps} loss={loss.item():.4f}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    \"\"\"Evaluate accuracy on overall, per-group, and worst group.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    correct_g = {0:0, 1:0}\n",
    "    total_g   = {0:0, 1:0}\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        pred = model(xb).argmax(1)\n",
    "        correct += (pred==yb).sum().item()\n",
    "        total   += yb.numel()\n",
    "        for g in (0,1):\n",
    "            mask = (yb==g)\n",
    "            if mask.any():\n",
    "                correct_g[g] += (pred[mask]==yb[mask]).sum().item()\n",
    "                total_g[g]   += mask.sum().item()\n",
    "    overall = correct / total\n",
    "    acc_g = {g: (correct_g[g]/total_g[g] if total_g[g]>0 else float('nan')) for g in (0,1)}\n",
    "    worst = min(acc_g.values())\n",
    "    return overall, acc_g, worst\n",
    "\n",
    "# =========================\n",
    "# Main loop: multi-seed experiments\n",
    "# =========================\n",
    "grid = np.arange(0.0, 1.0+1e-8, GRID_STEP)\n",
    "acc_overall_map = {float(p4): [] for p4 in grid}\n",
    "acc_worst_map   = {float(p4): [] for p4 in grid}\n",
    "acc_min_map     = {float(p4): [] for p4 in grid}\n",
    "acc_maj_map     = {float(p4): [] for p4 in grid}\n",
    "\n",
    "erm_overall_list, erm_worst_list, erm_min_list, erm_maj_list = [], [], [], []\n",
    "\n",
    "t0_all = time.time()\n",
    "\n",
    "Xtr_all, ytr_all, Xte_all, yte_all = load_mnist_49()\n",
    "print(\"Filtered train:\", Xtr_all.shape, torch.bincount(ytr_all).tolist())\n",
    "print(\"Filtered test :\",  Xte_all.shape, torch.bincount(yte_all).tolist())\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n========== SEED {seed} ==========\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    Xte, yte = build_test_with_ratio(Xte_all, yte_all, maj_ratio=TEST_MAJ_RATIO, total=1000)\n",
    "    print(\"Test counts (4,9):\", torch.bincount(yte).tolist())\n",
    "\n",
    "    Xtr, ytr = sample_imbalanced_train(Xtr_all, ytr_all, TOTAL_TRAIN, IMBALANCE_RATIO, seed)\n",
    "    Xtr_mod = Xtr.clone()\n",
    "    p_train_counts = torch.bincount(ytr, minlength=2).float()\n",
    "    p_train_vec = (p_train_counts / p_train_counts.sum()).to(device)\n",
    "    print(\"Imbalanced train counts:\", p_train_counts.tolist(), \"  p_train:\", (p_train_vec.cpu().numpy().round(6)).tolist())\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(Xtr_mod, ytr), batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    test_loader  = DataLoader(TensorDataset(Xte, yte),     batch_size=1000,    shuffle=False)\n",
    "\n",
    "    # === ERM (p = p_train) ===\n",
    "    print(\"\\n=== ERM (p = p_train) ===\")\n",
    "    model_erm = LeNet5().to(device)\n",
    "    train_steps(model_erm, train_loader, steps=ERM_STEPS, p_vec=p_train_vec, p_train_vec=p_train_vec)\n",
    "    erm_overall, erm_accg, erm_worst = evaluate(model_erm, test_loader)\n",
    "    print(f\"ERM test Acc: overall={erm_overall:.4f}, 4(min)={erm_accg[0]:.4f}, 9(maj)={erm_accg[1]:.4f}, worst={erm_worst:.4f}\")\n",
    "    erm_overall_list.append(erm_overall)\n",
    "    erm_worst_list.append(erm_worst)\n",
    "    erm_min_list.append(erm_accg[0])\n",
    "    erm_maj_list.append(erm_accg[1])\n",
    "\n",
    "    # === Grid search (from scratch) ===\n",
    "    print(\"\\n=== Grid search (from scratch) ===\")\n",
    "    for p4 in grid:\n",
    "        p4 = float(p4)\n",
    "        p_vec = torch.tensor([p4, 1.0-p4], dtype=torch.float32, device=device)\n",
    "        model = LeNet5().to(device)\n",
    "        train_steps(model, train_loader, steps=STEPS_PER_GRID, p_vec=p_vec, p_train_vec=p_train_vec)\n",
    "        overall, accg, worst = evaluate(model, test_loader)\n",
    "\n",
    "        acc_overall_map[p4].append(overall)\n",
    "        acc_worst_map[p4].append(worst)\n",
    "        acc_min_map[p4].append(accg[0])\n",
    "        acc_maj_map[p4].append(accg[1])\n",
    "\n",
    "        print(f\"  p4={p4:.2f} -> overall={overall:.4f} | 4={accg[0]:.4f} 9={accg[1]:.4f} | worst={worst:.4f}\")\n",
    "\n",
    "print(f\"\\nTotal wall time: {(time.time()-t0_all)/60:.1f} min\")\n",
    "\n",
    "# =========================\n",
    "# Aggregate results\n",
    "# =========================\n",
    "def mean_std(arr):\n",
    "    return float(np.mean(arr)), (float(np.std(arr, ddof=1)) if len(arr) > 1 else 0.0)\n",
    "\n",
    "erm_overall_mean, erm_overall_std = mean_std(erm_overall_list)\n",
    "erm_worst_mean,  erm_worst_std  = mean_std(erm_worst_list)\n",
    "erm_min_mean,    erm_min_std    = mean_std(erm_min_list)\n",
    "erm_maj_mean,    erm_maj_std    = mean_std(erm_maj_list)\n",
    "\n",
    "print(\"\\n==== Aggregated over seeds ====\")\n",
    "print(f\"ERM overall = {erm_overall_mean:.4f} ± {erm_overall_std:.4f}\")\n",
    "print(f\"ERM worst   = {erm_worst_mean:.4f} ± {erm_worst_std:.4f}\")\n",
    "print(f\"ERM min(4)  = {erm_min_mean:.4f} ± {erm_min_std:.4f}\")\n",
    "print(f\"ERM maj(9)  = {erm_maj_mean:.4f} ± {erm_maj_std:.4f}\")\n",
    "\n",
    "p4s = np.array(list(acc_overall_map.keys())); p4s.sort()\n",
    "\n",
    "def agg_curve(metric_map):\n",
    "    means, stds = [], []\n",
    "    for p in p4s:\n",
    "        m, s = mean_std(metric_map[p])\n",
    "        means.append(m); stds.append(s)\n",
    "    return np.array(means), np.array(stds)\n",
    "\n",
    "overall_mean, overall_std = agg_curve(acc_overall_map)\n",
    "worst_mean,   worst_std   = agg_curve(acc_worst_map)\n",
    "min_mean,     min_std     = agg_curve(acc_min_map)\n",
    "maj_mean,     maj_std     = agg_curve(acc_maj_map)\n",
    "\n",
    "best_overall_idx = int(np.argmax(overall_mean))\n",
    "best_worst_idx   = int(np.argmax(worst_mean))\n",
    "print(f\"[Overall-mean best] p4={p4s[best_overall_idx]:.2f}, mean overall={overall_mean[best_overall_idx]:.4f}±{overall_std[best_overall_idx]:.4f}, \"\n",
    "      f\"mean worst={worst_mean[best_overall_idx]:.4f}±{worst_std[best_overall_idx]:.4f}\")\n",
    "print(f\"[Worst-mean  best] p4={p4s[best_worst_idx]:.2f}, mean overall={overall_mean[best_worst_idx]:.4f}±{overall_std[best_worst_idx]:.4f}, \"\n",
    "      f\"mean worst={worst_mean[best_worst_idx]:.4f}±{worst_std[best_worst_idx]:.4f}\")\n",
    "\n",
    "# =========================\n",
    "# Plot curves\n",
    "# =========================\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(p4s, overall_mean, label='Overall Acc (mean)')\n",
    "plt.fill_between(p4s, overall_mean - overall_std, overall_mean + overall_std, alpha=0.2)\n",
    "\n",
    "plt.plot(p4s, worst_mean, label='Worst-Group Acc (mean)')\n",
    "plt.fill_between(p4s, worst_mean - worst_std, worst_mean + worst_std, alpha=0.2)\n",
    "\n",
    "plt.plot(p4s, min_mean, label='Minority (digit 4) Acc (mean)')\n",
    "plt.fill_between(p4s, min_mean - min_std, min_mean + min_std, alpha=0.2)\n",
    "\n",
    "plt.axvline(x=0.5, linestyle='--', label='LR p4 = 0.5 (test prior)')\n",
    "plt.axvline(x=P4_TRAIN_PRIOR, linestyle=':', label='Train prior p4')\n",
    "plt.xlabel('Group weight p4 (digit 4)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs p4 (From Scratch, multi-seed mean ± std)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
